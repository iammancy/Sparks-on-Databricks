{"cells":[{"cell_type":"markdown","source":["#ETL (UNSTRUCTURED---->STRUCTURED)"],"metadata":{}},{"cell_type":"code","source":["from pyspark import SQLContext"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.functions import *\nimport json\n#import pandas as pd"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["sqlContext = SQLContext.getOrCreate(sc)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["Flat_Frame = sqlContext.read.json(\"/FileStore/tables/ssze2x0r1466492117327/comments.json\").select(explode(\"data\").alias(\" \"))\n##import a json file as a dataframe, flatten as a list. Then pass this as the argument to make another dataframe."],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["Flat_Frame.printSchema()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["Flat_Fr2 = sqlContext.createDataFrame(Flat_Frame.select(\" .message\").collect())"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(Flat_Fr2)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["##dtaset=Flat_Fr2.as[String]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["import re\n##from pyspark import  \nfilterDF = Flat_Fr2.filter(col(\"message\")== \"What a dream to live there :)\")\n##lines = sqlContext.read.text(\"/wikipedia\").as[String]\n##display(Flat_Fr2.select(explode(\"message\",\"product\") {lambda message:}))\ndisplay(filterDF)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["display(filterDF)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["Rdd =  Flat_Fr2.map(str)\ntype(Rdd)\nRdd.collect()\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#rdd_str.toRDD\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#display(Rdd.take(Rdd.count()))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["import re\nrdd_str.map(lambda x:re.sub(r'',\"\" ,x)).collect()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Hardcoded Sentiment Analysis Positive\nimport re\n\npositive_count = 0\npositive = {'21 Day Fix' : \"good\", 'Focus T25' : \"good\", 'CIZE': \"good\", 'INSANITY':\"good\", 'Brazil Butt Fit':\"good\", 'Tai Cheng': \"good\", 'Hip Hop Abs':\"good\", 'P9OX':\"good\", 'Turbo':\"good\", 'Slim in 6':\"good\", 'effective':\"good\" }\nfor row in Rdd.collect():\n  for key,value in positive.items():\n    ns= ''.join(str(e) for e in row)\n    if re.search(key, ns,re.IGNORECASE):\n      positive_count = positive_count +1\n      print ns\nprint 'The no of Positive Comments :' +str(positive_count)  \n  "],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["import re\nimport nltk\nfrom nltk.corpus import wordnet\nnltk.download(\"wordnet\")\nset_pstive = wordnet.synsets(\"good\")\n\n\nfor row in rdd_str.collect():\n  while set_pstive:\n    ps=''.join(str())"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Hardcoded negative mapping\nnegative = {'worst': \"bad\",'pathetic':\"bad\",'scam':\"bad\",'fake':\"bad\",'ripoff':\"bad\",'not effective':\"bad\",'not worthy':\"bad\",'too expensive':\"bad\",'bad':\"bad\",'poor':\"bad\", 'complaint':\"bad\", 'complain':\"bad\"}\nnegative_count = 0\nfor row in Rdd.collect():\n  for key,value in negative.items():\n    ns= ''.join(str(e) for e in row)\n    if re.search(key, ns,re.IGNORECASE):\n      negative_count = negative_count +1\n      print ns\n    #print (type(ns))\nprint 'No. of negative comments '+str(negative_count)  \n  "],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\n\n#word_tokens = word_tokenize(' '.join(str(e) for e in list11))\n\n\n#type(word_tokens)  \n#stop_words=set(stopwords.words('english'))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["import nltk\nfrom nltk.sentiment import SentimentAnalyzer\nfrom nltk.sentiment.util import * \nfrom nltk.corpus import subjectivity"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from nltk.classify import NaiveBayesClassifier"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#this is with vader"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["for row in Rdd.collect():\n  #for key,value in positive.items():\n  ns= ''.join(str(e) for e in row)\n    #if re.search(key, ns,re.IGNORECASE):\n      #positive_count = positive_count +1\n  print ns\n  type(ns)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["from nltk import tokenize\nnltk.download(\"punkt\")"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["for row in Rdd.collect():\n  ns= ''.join(str(e) for e in row)\n  lines_list = tokenize.sent_tokenize(ns)\n  print ns"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["for row in Rdd.collect():\n  ns= ''.join(str(e) for e in row)\n  print ns"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#sentences.extend(tricky_sentences)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download(\"vader_lexicon\")\nsid = SentimentIntensityAnalyzer()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["positives = 0\nnegatives = 0\npos_string= \" \"\nneg_string= \" \"\nfor sentences in Rdd.collect():\n  ns= ''.join(str(e) for e in sentences)\n  print(ns)\n  ss = sid.polarity_scores(ns)\n  print ss\n  print ss['compound']\n  if ss['compound']>0:\n    #pos_string = ns+pos_string\n    positives = positives+1\n  if ss['compound']<0:\n    #neg_string = ns+neg_string\n    negatives = negatives+1\n#print \"POSITIVES\",pos_string\n#print \"NEGATIVES\",neg_string\nprint \"Total no. of positives\",positives\nprint \"Total no. of negatives\",negatives\n    \n  \n  \n  #for k in sorted(ss):\n  #print ss\n  #print\n  "],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":30}],"metadata":{"name":"NewNB","notebookId":4245595074120918},"nbformat":4,"nbformat_minor":0}
